---
title: "Informedb Software Quality Metrics"
author: "Liam Whitenack"
date: "`r Sys.Date()`"
documentclass: article
geometry: margin=1in
fontsize: 11pt
output:
  pdf_document:
    toc: false
    df_print: kable
    fig_caption: false
    number_sections: false
    dev: pdf
    highlight: tango
  html_document:
    theme: default
    self_contained: true
    toc: false
    df_print: kable
    fig_caption: false
    number_sections: false
    smart: true
    dev: svg
---

This project was done as an Internship Report to be presented at the end of the year. It is made in an attempt to find the eight Software Quality Metrics found in the PowerPoint attached. 

```{r setup, include = FALSE}
# Set knitr options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  fig.width = 5,
  fig.asp = 0.618,
  out.width = "70%",
  dpi = 120,
  fig.align = "center",
  cache = FALSE
)
# Load required packages
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(infer))
suppressPackageStartupMessages(library(modelr))
suppressPackageStartupMessages(library(broom))
suppressPackageStartupMessages(library(rlang))
suppressPackageStartupMessages(library(plotly))
GitLab <- read_csv("Informedb Gitlab Data.csv")
Jira <- read_csv("Informedb Jira Data.csv")
```

**All data is collected from the Informedb project. The project has assigned issue resolution data on Jira and Has commit data on GitLab that was collected and organized to analyze in RStudio.**  

## Question of Interest  
The issue I will be addressing will be the military’s request for organized and presented data on projects. Software Quality Metrics are useful for analyzing trends and discovering patterns that lead to productivity. This project is being developed because the military would like reports on these metrics but doing some data analysis could show how the company can improve the efficiency of their software development.  
I will be addressing the issue by mining all the data available on Jira and GitHub for the Informedb Project on the company’s progress in finding issues, starting work on said issues, and resolving the issues. The project will require me to find eight different Software Quality Metrics:  
•	defect Trends  
•	Total Defects found in the last 4 weeks  
•	MTTR – Mean time to repair  
•	defect Removal Efficiency  
•	Number of failed fix attempts (external)  
•	Number of failed fix attempts (internal)  
•	Change failure rate within release cycle  
•	Automated Code Coverage (in percent)  

```{r}
GitLab <- GitLab %>%
  mutate(
    author_date = as.Date(strptime(author_date, 
                                   format = "%a %b %d %H:%M:%S %Y")),
    committer_date = as.Date(strptime(committer_date, 
                                      format = "%a %b %d %H:%M:%S %Y")) 
    # read columns as dates instead of characters
  )

GitLab_reduced <- GitLab %>%
  select(
    author_date,
    committer_date
  )
```
This code block takes all of the data from GitLab and makes it usable. It then outputs it all into a much simpler dataset which only contains the columns being used. 
```{r}
n <- 0
counter <- 0
while(n < 1){
  counter <- counter + 1
  if(Jira$`Issue Type`[counter] == "Bug" || Jira$`Issue Type`[counter] == "Pre-Release Bug"){
    my_vec <- counter
    n = 1
    counter = counter + 1
  }
}
for(i in counter:length(Jira$`Issue Type`)){
  if(Jira$`Issue Type`[i] == "Bug" || Jira$`Issue Type`[i] == "Pre-Release Bug"){
    my_vec <- c(my_vec, i)
  }
}
```
```{r}
Jira_bugs <- Jira[c(my_vec), ]
```


```{r}
for(i in 1:length(Jira_bugs$Status)){
  Jira_bugs$Resolved[i]<-NA
}
for(i in 1:length(Jira_bugs$Status)){
        if(Jira_bugs$Status[i] == "Resolved"){
          Jira_bugs$Resolved[i]<-Jira_bugs$Updated[i]
        }
}
```
```{r}
Jira_Sprints <- Jira_bugs %>%
  select(
    Sprint,
    Sprint_1,
    Sprint_2,
    Sprint_3,
    Sprint_4
  )
```

```{r}
for(i in 1:length(Jira_bugs$Status)){
  if(is.na(Jira_bugs$Sprint_4[i]) == FALSE){
  Jira_bugs$n_sprints[i]<-5
  }
  else if(is.na(Jira_bugs$Sprint_3[i]) == FALSE){
    Jira_bugs$n_sprints[i]<-4
  }
  else if(is.na(Jira_bugs$Sprint_2[i]) == FALSE){
    Jira_bugs$n_sprints[i]<-3
  }
  else if(is.na(Jira_bugs$Sprint_1[i]) == FALSE){
    Jira_bugs$n_sprints[i]<-2
  }
  else if(is.na(Jira_bugs$Sprint[i]) == FALSE){
    Jira_bugs$n_sprints[i]<-1
  }
  else{
    Jira_bugs$n_sprints[i] <-0
  }
}
```
This code block updates the "Resolved" column. The resolved column only contains a value if the row's value in the Status column is "Resolved". If the logical statement is TRUE then the Resolved column's value is the same as the Updated column.
```{r}
Jira_bugs <- Jira_bugs %>%
    mutate(
      Priority = recode(
       Priority,
          `1 - Trivial` = "R1",
          `Trivial` = "R1",
          `2 - Minor` = "R1",
          `Minor` = "R1",
          `3 - Major` = "R2",
          `Major` = "R2",
          `4 - Critical` = "R3",
          `Critical` = "R3",
          `5 - Blocker` = "R4",
          `Blocker` = "R4",
      ), # Rename each value to R1, R2, R3, and R4, the military's preferred terms.
      completed = recode(
        Status,
        Resolved = 1,
        Done = 0,
        Closed = 0,
        `In Progress` = 0,
        `Ready For Review` = 0,
        `Ready For Test` = 0,
        Reopened = 0,
        .default = 0
      ), # set the value of each resolved issue to 1 for computational purposes
      open = recode(
        Status,
        Resolved = 0,
        Done = 1,
        Closed = 0,
        `In Progress` = 1,
        `Ready For Review` = 1,
        `Ready For Test` = 1,
        Reopened = 1,
        .default = 0
      ), # set the value of each resolved issue to 1 for computational purposes
      failed_fix = recode(
        Status,
        Resolved = 0,
        Done = 0,
        Closed = 0,
        `In Progress` = 0,
        `Ready For Review` = 0,
        `Ready For Test` = 0,
        Reopened = 1,
        .default = 0
      ), # set the value of each resolved issue to 1 for computational purposes
      Parent = `Parent id`,
      Issue = `Issue id`,
      Type = `Issue Type`,
      date_created = as.Date(strptime(Created, format = "%m/%d/%Y %H:%M")),
      date_updated = as.Date(strptime(Updated, format = "%m/%d/%Y %H:%M")),
      date_resolved = as.Date(strptime(Resolved, format = "%m/%d/%Y %H:%M")), 
      # read columns as dates instead of characters
      time_spent = date_updated - date_created, 
      # create the time_spent parameter, which is computed by finding 
      # the difference between the date of creation and last day updated
      repair_time = date_resolved - date_created 
      # create the repair time parameter, which is computed by finding 
      # the difference between the date of creation and day resolved
    )
```
```{r}
Jira_reduced <- Jira_bugs %>%
  select(
    Priority,
    completed,
    open,
    failed_fix,
    date_created,
    date_updated,
    date_resolved,
    time_spent,
    repair_time,
    Assignee,
    n_sprints
  )
```
This code block renames columns and makes them usable. At the end, it makes a new dataset with only the necessary columns. 

```{r}
Number_of_weeks <- (max(Jira_reduced$date_updated) - min(Jira_reduced$date_created))/7
Number_of_weeks <- as.numeric(Number_of_weeks)
```
This code block calculates the number of weeks.
```{r}
Jira_reduced %>%
  ggplot() +
  geom_histogram(aes(x = date_created, fill = Priority), bins = 20) +
  labs(title = "Defect Trends Histogram") +
  xlab("Issue Date")
```
This graph shows the defect Trends as they are shown in the PowerPoint from the Navy. This graph shows the number of different issues reported, with the colors indicating the Priority of the issue. 
```{r}
Summary_Statistics <- Jira_reduced %>%
  group_by(Priority) %>%
  summarise( 
    Defects = n(),
    `Defects in four weeks` = n() / (Number_of_weeks / 4),
    `MTTR` = (mean((repair_time), na.rm = TRUE)),
    FFA = sum(failed_fix),
    DRE = sum(completed) / n(),
    Open = sum(open)
  )
(Summary_Statistics)
```
This graph shows some summary statistics, most of which are estimated to a degree. Each parameter is calculated for each priority level.  
•	Defects- This column shows the total number of defects.  
•	Defects in four weeks- This column shows the average number of defects over four weeks.  
•	MTTR (mean time to repair)- This column shows the average number of days spent from the creation of the project to the day it was last updated (only in cases where the status of the project is “Resolved”).
•	FFA (Failed Fix Attempts)- This column states the number of issues that have to be tested still.  
•	DRE (defect removal efficiency)- This column shows the number of total issues resolved divided by the number of total issues. 
•	Open- the number of projects that are left as "open"

